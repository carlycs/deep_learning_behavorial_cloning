{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all modules imported\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import json\n",
    "import os.path\n",
    "import pickle\n",
    "import h5py\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pandas\n",
    "import math\n",
    "print(\"all modules imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all keras needed modules imported\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Lambda, ELU, Dropout, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "print(\"all keras needed modules imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All needed Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the image from the given path and convert BGR to RGB\n",
    "def readImage(image_path):\n",
    "    image_cv2 = cv2.imread(image_path)\n",
    "    image_color = cv2.cvtColor(image_cv2,cv2.COLOR_BGR2RGB)\n",
    "    return image_color\n",
    "\n",
    "#shuffling is done in generator and this is no longer used\n",
    "def shuffle(images, labelx):\n",
    "    idx = np.arange(len(x))\n",
    "    np.random.shuffle(idx)\n",
    "    images = images[idx]\n",
    "    labels = labels[idx]\n",
    "    return (x, y)\n",
    "\n",
    "#normalize the images - note that this is done through the lambda in the model and not being used\n",
    "def normalize(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [-0.5, 0.5]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a = 0.5\n",
    "    b = -0.5\n",
    "    greyscale_min = 0\n",
    "    greyscale_max = 255\n",
    "    return a + ( ( (image_data - greyscale_min)*(b - a) )/( greyscale_max - greyscale_min ) )\n",
    "\n",
    "#convert to YUV now does as a convolution layer at beginning of model\n",
    "def convertToYUV(image):\n",
    "    converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    return converted_image\n",
    "\n",
    "def flipImage(img):\n",
    "    flipped_image = img.copy()\n",
    "    flipped_image = cv2.flip(img, 1)\n",
    "    # num_rows, num_cols = img.shape[:2]\n",
    "    # rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 30, 1)\n",
    "    # img_rotation = cv2.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "    return flipped_image\n",
    "\n",
    "#vivek yadav's brightness changer for augmentation\n",
    "def augment_brightness_camera_images(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    #print(random_bright)\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "#vivek yadav's translation for augmentation\n",
    "def trans_image(image,steer,trans_range):\n",
    "    # Translation\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steer_ang = steer + tr_x/trans_range*2*.2\n",
    "    tr_y = 40*np.random.uniform()-40/2\n",
    "    #tr_y = 0\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    image_tr = cv2.warpAffine(image,Trans_M,(img_cols,img_rows))\n",
    "\n",
    "    return image_tr,steer_ang\n",
    "\n",
    "def cropImage(image):\n",
    "     image_clipped = image[math.floor(image.shape[0]/5):image.shape[0]-25, 0:image.shape[1]]\n",
    "     return image_clipped\n",
    "\n",
    "def resizeImage(image):\n",
    "    image_resized =  cv2.resize(image, (img_cols, img_rows),interpolation=cv2.INTER_AREA)\n",
    "    return image_resized\n",
    "\n",
    "def processImage(image, angle):\n",
    "    #image = readImage(image)\n",
    "    image = cropImage(image)\n",
    "    image = resizeImage(image)\n",
    "    image = augment_brightness_camera_images(image)\n",
    "    image, angle = trans_image(image, angle, 100)\n",
    "    #image = convertToYUV(image)\n",
    "    random_int = np.random.randint(100)\n",
    "    if random_int > 50: # flip the image half the time\n",
    "        image = flipImage(image)\n",
    "        angle = -angle\n",
    "    return image, angle\n",
    "\n",
    "#generator\n",
    "def generate(images, labels, batch_size):\n",
    "    batch_images = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    batch_labels = np.zeros(batch_size)\n",
    "    total = 0\n",
    "    while 1:\n",
    "        for i in range(batch_size):\n",
    "            if total >= len(images):\n",
    "                total = 0\n",
    "            random_int = np.random.randint(len(images))\n",
    "            image = images[random_int]\n",
    "            label = labels[random_int]\n",
    "            batch_images[i], batch_labels[i]= processImage(image, label)\n",
    "            total = total + 1\n",
    "        yield batch_images, batch_labels\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_cols = 200\n",
    "img_rows = 66\n",
    "batch_size = 64\n",
    "nb_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training on the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the images from the data folder\n",
    "data = pandas.read_csv('driving_log.csv', header = None)\n",
    "data.columns = [\"center_images\",\"left_images\",\"right_images\",\"steering\",\"brake\",\"throttle\",\"speed\"]\n",
    "angles = data['steering']\n",
    "center_images = data['center_images']\n",
    "left_images = data['left_images']\n",
    "right_images = data['right_images']\n",
    "\n",
    "## Prepare the training and test data -----------\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "#center images\n",
    "for i,image in enumerate(center_images):\n",
    "    if not i == 0: #first record was None probably because of the header row in CSV\n",
    "        image_center = readImage(center_images[i])\n",
    "        #image_left = readImage(left_images[i])\n",
    "        #image_right = readImage(right_images[i])\n",
    "        angle_center = float(angles[i])\n",
    "        angle_left = angle_center + .25 #((0.1*angle_center)+.1)\n",
    "        angle_right = angle_center - .25 #((0.1*angle_center)+.1)\n",
    "        if(i%19==0):\n",
    "            X_test.append(image_center)\n",
    "            y_test.append(angle_center)\n",
    "            #X_test.append(image_left)\n",
    "            y_test.append(angle_left)\n",
    "            #X_test.append(image_right)\n",
    "            y_test.append(angle_right)\n",
    "        if angle_center == 0:\n",
    "            random_int = np.random.randint(100)\n",
    "            if random_int > 50:\n",
    "                X_train.append(image_center)\n",
    "                y_train.append(angle_center)\n",
    "        else:\n",
    "            X_train.append(image_center)\n",
    "            y_train.append(angle_center)\n",
    "        #X_train.append(image_left)\n",
    "        y_train.append(angle_left)\n",
    "        #X_train.append(image_right)\n",
    "        y_train.append(angle_right)\n",
    "\n",
    "    \n",
    "#convert list to np.array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#reshape the arrays\n",
    "X_train = X_train.reshape(len(X_train),160,320,3)\n",
    "X_test = X_test.reshape(len(X_test),160,320,3)\n",
    "train_labels = np.zeros(len(y_train))\n",
    "test_labels = np.zeros(len(y_test))\n",
    "for i,label in enumerate(y_train):\n",
    "    train_labels[i] = label\n",
    "\n",
    "for i,label in enumerate(y_test):\n",
    "    test_labels[i] = label\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on Nvidia model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 200, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 66, 200, 3)    12          lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 31, 98, 24)    1824        convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 31, 98, 24)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 14, 47, 36)    21636       elu_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 14, 47, 36)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 5, 22, 48)     43248       elu_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 5, 22, 48)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 3, 20, 64)     27712       elu_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 3, 20, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 1, 18, 64)     36928       elu_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_5 (ELU)                      (None, 1152)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      elu_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_6 (ELU)                      (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        elu_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_7 (ELU)                      (None, 50)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         elu_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_8 (ELU)                      (None, 10)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          elu_8[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 252,231\n",
      "Trainable params: 252,231\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape = (img_rows,img_cols,3)\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1., #normalization\n",
    "            input_shape=img_shape))\n",
    "#change color space\n",
    "model.add(Convolution2D(3,1,1, subsample=(1,1), border_mode=\"valid\", init=\"he_normal\"))\n",
    "# Nvidia model\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), border_mode=\"valid\", init=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), border_mode=\"valid\", init=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), border_mode=\"valid\", init=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1,1), border_mode=\"valid\", init=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1,1), border_mode=\"valid\", init=\"he_normal\"))\n",
    "model.add(Flatten())\n",
    "model.add(ELU())\n",
    "model.add(Dense(100, init=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(Dense(50, init=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(Dense(10, init=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "adam = Adam(lr=1e-4)\n",
    "model.compile(loss='mse',\n",
    "              optimizer=adam,\n",
    "              metrics=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.1921Epoch 00000: saving model to ./model00.h5\n",
      "19200/19200 [==============================] - 271s - loss: 0.1916 - val_loss: 0.1290\n",
      "Epoch 2/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0717Epoch 00001: saving model to ./model01.h5\n",
      "19200/19200 [==============================] - 280s - loss: 0.0716 - val_loss: 0.1346\n",
      "Epoch 3/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0684Epoch 00002: saving model to ./model02.h5\n",
      "19200/19200 [==============================] - 273s - loss: 0.0685 - val_loss: 0.1148\n",
      "Epoch 4/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0660Epoch 00003: saving model to ./model03.h5\n",
      "19200/19200 [==============================] - 276s - loss: 0.0659 - val_loss: 0.1213\n",
      "Epoch 5/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0653Epoch 00004: saving model to ./model04.h5\n",
      "19200/19200 [==============================] - 276s - loss: 0.0654 - val_loss: 0.1115\n",
      "Epoch 6/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0643Epoch 00005: saving model to ./model05.h5\n",
      "19200/19200 [==============================] - 273s - loss: 0.0643 - val_loss: 0.0868\n",
      "Epoch 7/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0635Epoch 00006: saving model to ./model06.h5\n",
      "19200/19200 [==============================] - 281s - loss: 0.0635 - val_loss: 0.1275\n",
      "Epoch 8/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0639Epoch 00007: saving model to ./model07.h5\n",
      "19200/19200 [==============================] - 280s - loss: 0.0639 - val_loss: 0.1365\n",
      "Epoch 9/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0630Epoch 00008: saving model to ./model08.h5\n",
      "19200/19200 [==============================] - 273s - loss: 0.0630 - val_loss: 0.1249\n",
      "Epoch 10/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0627Epoch 00009: saving model to ./model09.h5\n",
      "19200/19200 [==============================] - 276s - loss: 0.0627 - val_loss: 0.1240\n",
      "Epoch 11/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0624Epoch 00010: saving model to ./model10.h5\n",
      "19200/19200 [==============================] - 279s - loss: 0.0624 - val_loss: 0.1037\n",
      "Epoch 12/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0627Epoch 00011: saving model to ./model11.h5\n",
      "19200/19200 [==============================] - 280s - loss: 0.0627 - val_loss: 0.1360\n",
      "Epoch 13/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0626Epoch 00012: saving model to ./model12.h5\n",
      "19200/19200 [==============================] - 286s - loss: 0.0625 - val_loss: 0.1334\n",
      "Epoch 14/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0618Epoch 00013: saving model to ./model13.h5\n",
      "19200/19200 [==============================] - 268s - loss: 0.0618 - val_loss: 0.1547\n",
      "Epoch 15/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 00014: saving model to ./model14.h5\n",
      "19200/19200 [==============================] - 266s - loss: 0.0615 - val_loss: 0.1247\n",
      "Epoch 16/200\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 00015: saving model to ./model15.h5\n",
      "19200/19200 [==============================] - 276s - loss: 0.0602 - val_loss: 0.1012\n",
      "Epoch 17/200\n",
      "11904/19200 [=================>............] - ETA: 104s - loss: 0.0609"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"./model{epoch:02d}.h5\", verbose=1, save_best_only=False)\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generate(X_train, y_train, batch_size),\n",
    "    samples_per_epoch=batch_size * 300,\n",
    "    nb_epoch=nb_epochs,\n",
    "    verbose=1,\n",
    "    validation_data=generate(X_test, y_test, 100),\n",
    "    nb_val_samples=len(X_test),\n",
    "    callbacks=[checkpointer]\n",
    "  )\n",
    "\n",
    "#Save final weights and models\n",
    "print(\"Saving model:\")\n",
    "\n",
    "model.save_weights(\"./model.h5\", True)\n",
    "\n",
    "with open('./model.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
